import pandas as pd
import textdistance
import sqlglot
import numpy as np

from sql_executor import MySQLExecutor
from sql_schema_init import MySQLSchemaInitializer

class SQLEvaluator:
    """PUBLIC"""

    def __init__(self, candidates):
        self.candidates = candidates

    def get_heatmap(self, score_cmp) -> pd.DataFrame:
        index = [f"Query{i}" for i in range(len(self.candidates))]

        matches = pd.DataFrame(0.0, index=index, columns=index)

        for i0 in range(len(self.candidates)):
            index0 = index[i0]
            candidate0 = self.candidates[i0]

            for i1 in range(len(self.candidates)):
                index1 = index[i1]
                candidate1 = self.candidates[i1]
                
                matches.loc[index0, index1] = score_cmp(candidate0, candidate1)

        return matches

    def get_heatmap_score(self, heatmap) -> float:
        arr = np.array(heatmap)
        upper_triangle = arr[np.triu_indices(arr.shape[0], k=1)]
        
        # If there is only 1 candidate, consistency is perfect
        if len(upper_triangle) == 0:
            return 1.0
            
        return float(np.mean(upper_triangle))

    def get_score(self, score_function) -> pd.DataFrame:
        index = [f"Query{i}" for i in range(len(self.candidates))]

        scores = pd.DataFrame(0.0, index=index, columns=["score"])

        for i0 in range(len(self.candidates)):
            index0 = index[i0]
            candidate0 = self.candidates[i0]

            scores.loc[index0, "score"] = score_function(candidate0)

        return scores

class SQLValidityEvaluator(SQLEvaluator):
    """PUBLIC"""

    def __init__(self, candidates):
        super().__init__(candidates)

    def parsable_scores(self) -> pd.DataFrame:
        return self.get_score(self.__parsable_score)

    """PRIVATE"""

    def __parsable_score(self, s1: str) -> float:
        return (1.0 if self.__is_parsable_sql(s1) else 0.0)

    def __is_parsable_sql(self, query: str) -> bool:
        try:
            sqlglot.parse_one(query)
            return True
        except sqlglot.errors.ParseError:
            return False

class SQLSyntaxicEvaluator(SQLEvaluator):
    """PUBLIC"""

    def __init__(self, candidates):
        super().__init__(candidates)

    def exact_matches(self) -> pd.DataFrame:
        return self.get_heatmap(self._match)

    def levenhstein_normalized(self) -> pd.DataFrame:
        return self.get_heatmap(self._levenhstein_distance_normalized)

    def exact_matches_score(self) -> float:
        return self.get_heatmap_score(self.exact_matches())

    def levenhstein_normalized_score(self) -> float:
        return 1.0 - self.get_heatmap_score(self.levenhstein_normalized())

    """PRIVATE"""

    def _match(self, s1: str, s2: str) -> float:
        return 1.0 if (s1 == s2) else 0.0

    def _levenhstein_distance_normalized(self, s1: str, s2: str) -> float:
        words_s1 = s1.split()
        words_s2 = s2.split()

        max_len = max(len(words_s1), len(words_s2))

        return textdistance.levenshtein.distance(words_s1, words_s2) / max_len

class SQLStructuralEvaluator(SQLEvaluator): 
    """PUBLIC"""

    def __init__(self, candidates):
        super().__init__(candidates)

    def exact_matches(self) -> pd.DataFrame:
        return self.get_heatmap(self.__match)

    def levenhstein_normalized(self) -> pd.DataFrame:
        return self.get_heatmap(self.__levenhstein_distance_normalized)

    def exact_matches_score(self) -> float:
        return self.get_heatmap_score(self.exact_matches())

    def levenhstein_normalized_score(self) -> float:
        return 1.0 - self.get_heatmap_score(self.levenhstein_normalized())

    def __get_cluster_index(self, clusters, element):
        return ([cluster_i for cluster_index in range(len(clusters)) if candidate0 in clusters[cluster_index]])[0]

    # Union-Find Algorithm (generated by Gemini)
    def extract_levenhstein_clusters(self, threshold=0.01) -> list:
        heatmap = self.levenhstein_normalized().values
        
        candidates = self.candidates
        n = len(candidates)
        
        visited = set()
        clusters = []

        # 2. Iterate through every candidate
        for i in range(n):
            if i in visited:
                continue

            # 3. Start a new cluster with this candidate
            current_cluster_indices = {i}
            stack = [i]
            visited.add(i)

            # 4. Perform Search (DFS) to find all connected friends
            while stack:
                current_node = stack.pop()
                
                for neighbor in range(n):
                    if neighbor in visited:
                        continue
                    
                    # Check the distance
                    # Use <= threshold (e.g., 0.01) for "Close enough"
                    # Use == 0.0 for "Exact match only"
                    distance = heatmap[current_node][neighbor]
                    
                    if distance <= threshold:
                        visited.add(neighbor)
                        stack.append(neighbor)
                        current_cluster_indices.add(neighbor)

            # 5. Convert indices back to query strings
            cluster_queries = [candidates[idx] for idx in current_cluster_indices]
            clusters.append(cluster_queries)

        return clusters

    def get_ambiguity_score(self, threshold=0.01) -> float:
        clusters = self.extract_levenhstein_clusters(threshold=threshold)

        cluster_max_size = max(len(cluster) for cluster in clusters) if clusters else 0
        score = 1.0 - cluster_max_size / len(self.candidates)

        return score

    """PRIVATE"""

    def __ast_to_tokens(self, ast):
        return [
            node.key
            for node in ast.walk()
            if node.key is not None
        ]

    def __match(self, s1: str, s2: str) -> pd.DataFrame:
        norm1 = sqlglot.parse_one(s1).sql(pretty=False)
        norm2 = sqlglot.parse_one(s2).sql(pretty=False)

        return 1.0 if (norm1 == norm2) else 0.0

    def __levenhstein_distance_normalized(self, s1: str, s2: str) -> float:
        ast1 = sqlglot.parse_one(s1)
        ast2 = sqlglot.parse_one(s2)

        t1 = self.__ast_to_tokens(ast1)
        t2 = self.__ast_to_tokens(ast2)

        max_len = max(len(t1), len(t2))

        return textdistance.levenshtein.distance(t1, t2) / max_len

class SQLSemanticEvaluator(SQLEvaluator):
    """PUBLIC"""

    def __init__(self, candidates, schema, tables, tests, config, host):
        super().__init__(candidates)

        self.tests = tests
        self.llm_sql_executor = MySQLExecutor(
            host=host,
            user=config.get('mysql.username'),
            password=config.get('mysql.password'),
            database=config.get('mysql.database')
        )

        self.admin_initializer = MySQLSchemaInitializer(
            host=host,
            admin_user=config.get('mysql.admin_username'),
            admin_password=config.get('mysql.admin_password'),
            database=config.get('mysql.database')
        )
    
        self.schema = schema
        self.tables = tables
        self.candidates = candidates
        self.tests = tests

    def run_tests(self):
        index_candidates = [f"Query{i}" for i in range(len(self.candidates))]
        index_tests = [f"Test{j}" for j in range(len(self.tests))]

        results = {}

        for j in range(len(self.tests)):
            test = self.tests[j]
            index_test = index_tests[j]

            # RUN SCHEMA
            self.admin_initializer.set_schema(self.schema)
                    
            results[index_test] = {}
            for i in range(len(self.candidates)):
                # CLEAR
                # TODO: give involved tables and clear them
                for table in self.tables:
                    self.admin_initializer.set_schema(f"DELETE FROM {table};")
                self.admin_initializer.set_schema("DELETE FROM monthly_revenue;")
                # INSERT DATA
                self.admin_initializer.insert_data(test)

                candidate = self.candidates[i]
                index_candidate = index_candidates[i]

                results[index_test][index_candidate] = self.llm_sql_executor.run_query(candidate)

        return results
        

    
